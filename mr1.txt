
mkdir -p ~/wordcount_py
cd ~/wordcount_py

cat > input.txt <<EOF
Hadoop is simple
Hadoop is powerful
Hadoop runs everywhere
EOF

nano mapper.py

#!/usr/bin/env python
import sys

for line in sys.stdin:
    words = line.strip().split()
    for word in words:
        print("{0}\t1".format(word))


nano reducer.py

#!/usr/bin/env python
import sys

current_word = None
current_count = 0
word = None

for line in sys.stdin:
    line = line.strip()
    word, count = line.split('\t', 1)

    try:
        count = int(count)
    except ValueError:
        continue

    if current_word == word:
        current_count += count
    else:
        if current_word:
            print("{0}\t{1}".format(current_word, current_count))
        current_word = word
        current_count = count

if current_word == word:
    print("{0}\t{1}".format(current_word, current_count))



chmod +x mapper.py reducer.py
cat input.txt | ./mapper.py | sort | ./reducer.py


hdfs dfs -mkdir -p /user/cloudera/input
hdfs dfs -put -f input.txt /user/cloudera/input/
hdfs dfs -rm -r /user/cloudera/output_py

hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \
-files mapper.py,reducer.py \
-input /user/cloudera/input \
-output /user/cloudera/output_py \
-mapper mapper.py \
-reducer reducer.py

hdfs dfs -cat /user/cloudera/output_py/part-00000
